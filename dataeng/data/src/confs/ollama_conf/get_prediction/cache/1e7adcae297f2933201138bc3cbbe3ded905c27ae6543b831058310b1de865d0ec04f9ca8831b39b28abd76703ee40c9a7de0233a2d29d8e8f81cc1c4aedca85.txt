-  Le danger de favoriser des individus non visés par un entraînement sur des données biaisées. 

- Risque d'exclusion indirect pour les groupes n'ayant pas été inclus dans l'apprentissage du modèle.

- Possibilité d'une prédisposition discriminatoire envers des personnes non ciblées lors de l'utilisation d'un réseau neuronal dense.

- Préjugés inattendus à l'encontre de populations non représentées dans la base de données.

- Biais involontaire pouvant pénaliser les individus qui n'ont pas contribué à l'entraînement du modèle.

- Un risque latent de discrimination inversée envers des groupes marginalisés.

- La formation d'un algorithme potentiellement discriminatoire malgré l'absence d'intentionnalité.

- Perte de représentativité et biais inhérent à une base de données non exhaustive.

- Impact négatif sur les groupes non inclus dans le processus d'apprentissage du réseau neuronal.

-  Manifestation de discrimination indirecte envers des personnes non visées par la collecte de données.

- Déclenchement de préjugés inconscients à l'égard des individus n'ayant pas participé à l'entraînement.

- Risque de marginalisation accrue des populations déjà vulnérables.

- Un modèle entraîné sur une base restreinte pouvant engendrer des discriminations non intentionnelles.

- Biais systématique affectant négativement les personnes non représentées dans la donnée.

- Le spectre d'une discrimination inversée à l'œuvre malgré un objectif initial inclusif.

- La nécessité d'une attention particulière aux biais potentiels lors de la construction de données pour l'apprentissage automatique.

- Une réflexion approfondie sur les conséquences possibles de la formation d'un modèle sur une base de données non inclusive.

- L'importance de garantir une représentativité adéquate dans les données utilisées pour entraîner un réseau neuronal dense.



